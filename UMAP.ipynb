{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2830f71e",
   "metadata": {},
   "source": [
    "# Visualizing MSI Images with Parametric UMAP.\n",
    "\n",
    "Binning with m/z from 900 is used to create the segmentation.\n",
    "Then we train parametric umap using only the non noise bins, with 1 output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58a301-5ce5-499e-9324-370add2965c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.decomposition import non_negative_factorization\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from visualizations import get_colors, show_factorization_on_image, visualizations_from_explanations\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "NUM_COMPONENTS = 5\n",
    "_cmap = plt.cm.get_cmap('gist_rainbow')\n",
    "colors_for_components = [\n",
    "    np.array(\n",
    "        _cmap(i)) for i in np.arange(\n",
    "        0,\n",
    "        1,\n",
    "        1.0 /\n",
    "        NUM_COMPONENTS)]\n",
    "\n",
    "# Create the segmentation mask/\n",
    "ion_image = np.load(\"D:\\\\maldi\\\\tol_01_binarysearch_1_bin\\\\0.npy\")\n",
    "ion_image = ion_image[:, :, 600 :]\n",
    "H = np.load(\"h_cosegmentation.npy\")\n",
    "ion_image = ion_image / (1e-6 + np.median(ion_image, axis=-1)[:, :, None])\n",
    "vector = ion_image.reshape((-1, ion_image.shape[-1]))\n",
    "w_new, h_new, n_iter = non_negative_factorization(vector, H=H, W=None, n_components=NUM_COMPONENTS, update_H=False, random_state=0)\n",
    "explanations = w_new.transpose().reshape(NUM_COMPONENTS, ion_image.shape[0], ion_image.shape[1])\n",
    "explanations[4, :] = 0\n",
    "spatial_sum_visualization, global_percentile_visualization, normalized_sum, normalized_percentile = visualizations_from_explanations(ion_image, explanations, colors_for_components)\n",
    "segmentation_mask = normalized_sum.argmax(axis=0)\n",
    "segmentation_mask[ion_image.max(axis=-1) == 0] = 0\n",
    "display(Image.fromarray(spatial_sum_visualization))\n",
    "\n",
    "# Create the training data from the first image.\n",
    "ion_image = np.load(\"D:\\\\maldi\\\\tol_None_5_bins\\\\0.npy\")\n",
    "ion_image = ion_image / (1e-6 + np.median(ion_image, axis=-1)[:, :, None])\n",
    "ion_image[normalized_sum.argmax() == 3] = 0\n",
    "\n",
    "\n",
    "ion_image[segmentation_mask == 0] = 0\n",
    "training_data = ion_image[::2, ::2, :].reshape(-1, ion_image.shape[-1])\n",
    "training_data = training_data[training_data.max(axis=-1) > 0]\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef998737",
   "metadata": {},
   "source": [
    "# Define the parametric UMAP deep neural network.\n",
    "5005 outputs since we use the full range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572712f-8079-4f26-b924-a0ab6f57bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap.parametric_umap import ParametricUMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(5005,)),\n",
    "    tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "umap_model = ParametricUMAP(encoder=encoder, n_components=1, n_neighbors=50, n_training_epochs=1, dims=(5005,), run_eagerly=True).fit(training_data)\n",
    "\n",
    "umap_model.encoder.save(\"D:\\\\maldi\\\\parametric_umap_tol_None_5_bins.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d924c8b9-15d3-4c5b-9b59-d227913cfb8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1073004359.py, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 40\u001b[1;36m\u001b[0m\n\u001b[1;33m    for index, value in enumerate(np.unique(semantic_segmentation_labels):\u001b[0m\n\u001b[1;37m                                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "from umap.parametric_umap import load_ParametricUMAP\n",
    "import glob\n",
    "from parametric_umap import normalize_image_grayscale, image_histogram_equalization\n",
    "from utils import brain_nmf_semantic_segmentation\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import non_negative_factorization\n",
    "from visualizations import get_colors, get_qr_images, analyze_region_differences, get_difference_summary_table\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import cmapy\n",
    "\n",
    "encoder = tf.keras.models.load_model(\"D:\\\\maldi\\\\parametric_umap_tol_None_5_bins.keras\")\n",
    "lowres_paths = glob.glob(\"D:\\\\maldi\\\\tol_01_binarysearch_1_bin\\\\*.npy\")\n",
    "highres_paths = glob.glob(\"D:\\\\maldi\\\\tol_None_5_bins\\\\*.npy\")\n",
    "colors_maps=[\"Spectral\", \"PiYG\", \"RdGy\", \"seismic\"]\n",
    "#colors_maps = [\"gist_rainbow\", \"hsv\", \"seismic\", \"cividis\"]\n",
    "#colors_maps = [\"hsv\", \"twilight\", \"twilight_shifted\", \"seismic\"]\n",
    "for image_index, (path_for_segmentation, path_for_umap) in enumerate(zip(lowres_paths, highres_paths)):\n",
    "    semantic_segmentation_labels = brain_nmf_semantic_segmentation(path_for_segmentation)\n",
    "\n",
    "    ion_image = np.load(path_for_umap)\n",
    "    ion_image = ion_image / (1e-6 + np.median(ion_image, axis= -1)[:, :, None])\n",
    "    transformed = encoder.predict(ion_image.reshape(-1, ion_image.shape[-1]), batch_size=1000)\n",
    "    transformed = transformed.reshape((ion_image.shape[0], ion_image.shape[1]))\n",
    "    result = []\n",
    "    print('Colored image without region specific normalization')\n",
    "    num_bins = 2048\n",
    "    normalized_transformed = normalize_image_grayscale(transformed)\n",
    "    normalized_transformed = image_histogram_equalization(normalized_transformed, ion_image.max(axis=-1) > 0, num_bins) / (num_bins - 1)\n",
    "    colored_image = np.uint8(normalized_transformed*255)\n",
    "    colored_image = cv2.applyColorMap(colored_image, cmapy.cmap(colors_maps[0]))[:, :, ::-1]\n",
    "    display(Image.fromarray(colored_image))\n",
    "    print('1D UMAP with per region color mapping')\n",
    "\n",
    "    for index, value in enumerate(np.unique(semantic_segmentation_labels)):\n",
    "        mask = np.uint8(semantic_segmentation_labels == value) * 255\n",
    "        mask[ion_image.max(axis=-1) == 0] = 0\n",
    "        mask = cv2.medianBlur(mask, 3)\n",
    "        mask[ion_image.max(axis=-1) == 0] = 0\n",
    "        display(Image.fromarray(mask))\n",
    "        region_umap_representation = transformed.copy()\n",
    "        region_umap_representation[mask == 0] = 0\n",
    "\n",
    "        num_bins = 2048\n",
    "        region_umap_representation = normalize_image_grayscale(region_umap_representation)\n",
    "        region_umap_representation = image_histogram_equalization(region_umap_representation, mask, num_bins) / (num_bins - 1)\n",
    "        region_gray_image = np.uint8(region_umap_representation * 255)\n",
    "        region_color_image = cv2.applyColorMap(region_gray_image, cmapy.cmap(colors_maps[value]))\n",
    "        region_color_image = region_color_image[:, :, ::-1]\n",
    "        region_color_image[mask == 0] = 0\n",
    "        result.append(region_color_image)\n",
    "        \n",
    "        mzs_per_bin = 1\n",
    "        bins, digitized, region_pair_aucs = analyze_region_differences(ion_image, region_gray_image, mzs_per_bin, number_of_bins=3)\n",
    "        qr_images = get_qr_images(region_gray_image, bins, digitized, region_pair_aucs, mzs_per_bin, color_scheme=colors_maps[value])\n",
    "        display(Image.fromarray(np.hstack(qr_images)))\n",
    "        \n",
    "        top_mzs = {}\n",
    "        for (i, j) in region_pair_aucs:\n",
    "            _, full_range_aucs = region_pair_aucs[(i, j)]\n",
    "            top_mzs[(i, j)] = {k: v for k, v in sorted(full_range_aucs.items(),\n",
    "                                                key=lambda item: abs(item[1]))[::-1][:2000]}\n",
    "\n",
    "    \n",
    "    table = get_difference_summary_table(region_gray_image, digitized, bins, top_mzs, colors_maps[value])\n",
    "    display(Image.fromarray(table))\n",
    "    \n",
    "    result = np.array(result)\n",
    "    result = result.sum(axis=0)    \n",
    "    result[np.array(ion_image.max(axis=-1) == 0)] = 0\n",
    "    display(Image.fromarray(np.uint8(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118df0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
